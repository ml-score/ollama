{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059172ec-bcdb-4d69-9926-8eb064c6aa2a",
   "metadata": {},
   "source": [
    "### Chat with your unstructured CSVs with Llama3 and Ollama\n",
    "\n",
    "Some code inspired by Sascha Retter (https://blog.retter.jetzt/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90f6911e-5d51-4438-a76c-6be0093d56fd",
   "metadata": {},
   "source": [
    "##### Chat with local Llama3 Model via Ollama in KNIME Analytics Platform — Also extract Logs into structured JSON Files\n",
    "https://medium.com/p/aca61e4a690a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c8c70-cc08-43c0-8867-9d624f0219a4",
   "metadata": {},
   "source": [
    "##### Ask Questions from your CSV with an Open Source LLM, LangChain & a Vector DB\n",
    "https://www.tetranyde.com/blog/langchain-vectordb\n",
    "\n",
    "##### Document Loaders in LangChain\n",
    "https://medium.com/@varsha.rainer/document-loaders-in-langchain-7c2db9851123\n",
    "\n",
    "##### Unleashing Conversational Power: A Guide to Building Dynamic Chat Applications with LangChain, Qdrant, and Ollama (or OpenAI’s GPT-3.5 Turbo)\n",
    "https://medium.com/@ingridwickstevens/langchain-chat-with-your-data-qdrant-ollama-openai-913020ec504b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d60e71-b2fc-4a0b-b274-b7cb9ff452ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Document Loaders in LangChain\n",
    "# https://medium.com/@varsha.rainer/document-loaders-in-langchain-7c2db9851123\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# from langchain.vectorstores import Chroma\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# from langchain.llms import Ollama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "model = \"llama3:instruct\" # model needs already be available, already pulled with for example 'ollama run llama3:instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dc8613f-4331-4b0a-b7b2-dfb6b63df79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"How does a computer network work?\"\n",
    "v_num_docs = 10 # how many documents should be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92880f96-9217-458a-a1a8-9721f50c21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proxy configuration\n",
    "proxy = \"http://proxy.my-company.com:8080\"  # Replace with your proxy server and port\n",
    "# proxy = \"http://sia-lb.telekom.de:8080\"  # Replace with your proxy server and port\n",
    "proxy = \"\"\n",
    "os.environ['http_proxy'] = proxy\n",
    "os.environ['https_proxy'] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b3b972-1cea-4b10-906f-e09214a187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567e4f90-20d0-438f-9f6c-8a7149a1a357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a130e0e-482e-443e-9908-4b5019d13db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = newsgroups_train.data\n",
    "labels = newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91fc71b-4302-4a67-aa33-6def26c56c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': texts, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52be7df7-b433-40d7-ae29-3d96d98aef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_name'] = df['label'].map(dict(enumerate(newsgroups_train.target_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf7762a-b91d-4f83-a174-04bb2b71bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...      7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...      1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14   \n",
       "\n",
       "              label_name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd28b5d-b276-40c5-8b1a-41557ec8299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to a Parquet file\n",
    "df.to_parquet('../documents/csv/newsgroups_data.parquet')\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('../documents/csv/newsgroups_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd051ab-7018-4dd8-b888-099fd42f6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load the CSV information from a column\n",
    "# https://medium.com/@varsha.rainer/document-loaders-in-langchain-7c2db9851123\n",
    "loader = CSVLoader(\"../documents/csv/newsgroups_data.csv\", source_column=\"text\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d5605e0-afa3-4e88-8fc9-677f9073b1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a585f-495e-417f-92aa-430aa6e5a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "embedding_model = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685164b4-67c8-4c57-9b1a-8b22371fba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\" # the standard embedding model for\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf94ddb8-95c1-4dfb-9a5b-c58103f6a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = Chroma.from_documents(\n",
    "        documents,  embedding=embedding_model, persist_directory=\"../data/vectorstore/newsgroups\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f6d86a0-f5b2-446f-8958-2b1242ddd51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.chroma.Chroma"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chroma_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "675c6cc1-cc60-4ffc-b30c-6f4450f2db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk to demonstrate it will also work the next time\n",
    "chroma_db = Chroma(persist_directory=\"../data/vectorstore/newsgroups\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81350b00-200c-419c-9838-5ea44914e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.chroma.Chroma"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chroma_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b039ebb-76bc-4598-9cd9-4bdc29a0f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LLM model llama3:instruct\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = Ollama(model=model,\n",
    "            verbose=True,\n",
    "            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "print(f\"Loaded LLM model {llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ab14046-caad-4df3-b0ee-a40ebc2667c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RetrievalQA chain with the vector store retriever\n",
    "retriever = chroma_db.as_retriever(search_kwargs={\"k\": v_num_docs})  # Use the number of documents to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9042a07c-6234-47ea-a7ff-25b78e1f01d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it appears that there are several online and offline sources of images, data, etc. for computer networks. Some examples include:\n",
      "\n",
      "* Online sources:\n",
      "\t+ The Internet Relay Chat (IRC) system\n",
      "\t+ The Usenet news network\n",
      "\t+ Electronic mail (e-mail) systems like the ones used by the authors of the posts\n",
      "* Offline sources:\n",
      "\t+ Books and documents on computer networking and related topics\n",
      "\t+ Technical manuals and guides for specific hardware and software configurations\n",
      "\n",
      "It's worth noting that these sources are likely to be scattered across different platforms, networks, and devices, and may require some effort to access and utilize them effectively.\n",
      "\n",
      "In terms of the question \"How does a computer network work?\", it seems that there is already an answer provided within the context:"
     ]
    }
   ],
   "source": [
    "# Initialize the RetrievalQA chain with the vector store retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "# Use the 'invoke' method to handle the query instead of '__call__'\n",
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97a1ba-5f4c-4bd4-b2a3-d20c00f07c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ddf19-9c62-47d5-b766-d3dab137c1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
